<!DOCTYPE html>
<html>
  <head>    
  <meta http-equiv="content-type" content="text/html; charset=utf-8">    
  <meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport">    
  <title>
    Blog:7UP-hue
  </title>
  <script src="https://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js">
  </script>
  
<link rel="stylesheet" href="/css/style.css">

  
<link rel="stylesheet" href="/css/prism.css">
 
  
<script src="/js/prism.js"></script>

  
<script src="/js/app.js"></script>

  <script src="https://kit.fontawesome.com/487be84f99.js" crossorigin="anonymous"></script>
<meta name="generator" content="Hexo 5.4.2"></head>




  <body>
    <div class="container">
      <div class="layout-header">
        

  <header class="header header-last">

    <div class="title">
      <a href="/" class="logo" target="_self">
        <span>Blog:7UP-hue</span>
      </a>
    </div>
    <nav class="navbar">
      <ul class="menu">
        
          <li class="menu-item">
            <a href="/#main" class="menu-item-link" target="_self">
              <span data-text="主页">主页</span>
            </a>
          </li>
        
          <li class="menu-item">
            <a href="/archives" class="menu-item-link" target="_self">
              <span data-text="归档">归档</span>
            </a>
          </li>
        
          <li class="menu-item">
            <a href="/categories" class="menu-item-link" target="_self">
              <span data-text="分类">分类</span>
            </a>
          </li>
        
          <li class="menu-item">
            <a href="/tags" class="menu-item-link" target="_self">
              <span data-text="标签">标签</span>
            </a>
          </li>
        
          <li class="menu-item">
            <a href="/about" class="menu-item-link" target="_self">
              <span data-text="关于">关于</span>
            </a>
          </li>
         
      </ul>
    </nav>
  </header>

      </div>
      <div class="layout-body">
        <div id="main" class="index-continer">
  <div style="width: 90%"><article class="post posts article-post">
  <div class="post-title">
    <h2 class="title">
      数据挖掘考试复习
    </h2>
  </div>
  <div class="post-meta">
    <span class="post-time">
      2022-11-19
    </span>
  </div>
  <div class="post-content">
    <p>期末考试复习用~</p>
<span id="more"></span>
<h2 id="考试题型"><a href="#考试题型" class="headerlink" title="考试题型"></a>考试题型</h2><ol>
<li>名词解析（20分）<ul>
<li>中文写出英文全称，英文写出中文全称</li>
</ul>
</li>
<li>简答题（2个*20分）</li>
<li>综合题（40分）<ul>
<li>范围：十大算法、Close算法</li>
<li>内容：算法内容、伪代码</li>
</ul>
</li>
</ol>
<h2 id="重点算法"><a href="#重点算法" class="headerlink" title="重点算法"></a>重点算法</h2><ol>
<li>ID3：伪代码</li>
<li>k-means：伪代码</li>
<li>apriori：伪代码</li>
<li>PageRank：定义、伪代码</li>
<li>KNN：伪代码</li>
<li>EM：定义 </li>
<li>Close：闭合项集</li>
</ol>
<h2 id="第一章、第二章"><a href="#第一章、第二章" class="headerlink" title="第一章、第二章"></a>第一章、第二章</h2><blockquote>
<p>只考名词解释</p>
</blockquote>
<h3 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h3><ol>
<li><p>数据挖掘（Data Mining）</p>
<p>从广义的观点，数据挖掘是从大型数据集（可能是不完全的、有噪声的、不确定性的、各种存储形式的）中，挖掘隐含在其中的、人们事先完全不知道的、对决策有用的知识的完整过程。从狭义的观点，我们可以定义数据挖掘是从特定形式的数据集中提炼知识的过程。</p>
</li>
<li><p>web结构挖掘（Web structure mining）</p>
<p><strong>Web</strong> <strong>结构</strong>挖掘<strong>是指通过分析不同网页之间 的超链</strong>结构，发现许多蕴涵在 Web 内容之外的对我们有潜在价值的模式 和知识的过程。</p>
</li>
<li><p>大数据（big data）</p>
<p>指的是在传统数据处理应用软件不足以处理的大或复杂的数据集。大数据也可以定义为来自各种来源的大量非结构化或结构化数据。</p>
</li>
<li><p>人工智能（Artificial Inteligence）</p>
<p>人工智能是利用数字计算机或者数字计算机控制的机器模拟、延伸和扩展人的智能，感知环境、获取知识并使用知识获得最佳结果的理论、方法、技术及应用系统。</p>
</li>
<li><p>机器学习（Machine Leaning）</p>
<p>机器学习是计算机从数据中学习出规律和模式。以应用在新数据上做预测的任务。</p>
</li>
<li><p>知识工程（Knowledge Engineering）</p>
<p>知识工程是运用现代科学技术手段高效率、大容量的获得知识、信息的技术。目的是为了最大限度地提高人的才智和创造力，掌握知识和技能，提高人们借助现代化工具利用信息的能力，为智力开发服务。</p>
</li>
<li><p>信息检索（Information Retrieval）</p>
<p>广义的信息检索全称为“<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E4%BF%A1%E6%81%AF%E5%AD%98%E5%82%A8%E4%B8%8E%E6%A3%80%E7%B4%A2?fromModule=lemma_inlink">信息存储与检索</a>”，是指将信息按一定的方式组织和存储起来，并根据用户的需要找出有关信息的过程。狭义的信息检索为“<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E4%BF%A1%E6%81%AF%E5%AD%98%E5%82%A8%E4%B8%8E%E6%A3%80%E7%B4%A2?fromModule=lemma_inlink">信息存储与检索</a>”的后半部分，通常称为“信息查找”或“信息搜索”，是指从信息集合中找出用户所需要的有关信息的过程。</p>
</li>
<li><p>数据可视化（Data Visualization）</p>
<p>数据可视化，是关于数据视觉表现形式的<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF/3348043?fromModule=lemma_inlink">科学技术</a>研究。其中，这种数据的视觉表现形式被定义为，一种以某种概要形式抽提出来的信息，包括相应信息单位的各种属性和变量。</p>
<p> ……</p>
</li>
</ol>
<h2 id="第三章-关联规则挖掘理论和方法"><a href="#第三章-关联规则挖掘理论和方法" class="headerlink" title="第三章 关联规则挖掘理论和方法"></a>第三章 关联规则挖掘理论和方法</h2><h3 id="基本概念和解决方法"><a href="#基本概念和解决方法" class="headerlink" title="基本概念和解决方法"></a>基本概念和解决方法</h3><p>一般地，给定一个事务数据库，关联规则挖掘问题就是通过用户指定最小支持度和最小可信度来寻找强关联规则地过程。</p>
<p>几个概念：</p>
<ul>
<li>支持度：项目集$I_1$在数据集D上的支持度是指包含$I_1$的事务在D中所占的比例</li>
<li>频繁项目集：项目集$I$中满足最小支持度的非空子集</li>
<li>最大频繁项目集：频繁项目集中不被其他集合包含的集合</li>
<li>可信度：包含$I_1$和$I_2$ 的事务数与包含$I_1$的事务数之比</li>
<li>强关联规则：$D$ 在$I$上满足最小支持度和最小信任度的关联规则称为强关联规则。</li>
</ul>
<p>关联规则挖掘问题可以划分为两个子问题：</p>
<ol>
<li><p>发现频繁项目集</p>
<p>即根据最小支持度找到所有频繁项目集</p>
</li>
<li><p>生成关联规则</p>
<p>根据最小可信度，在最大频繁项目集中寻找强关联规则。</p>
</li>
</ol>
<h3 id="项目集空间理论"><a href="#项目集空间理论" class="headerlink" title="项目集空间理论"></a>项目集空间理论</h3><p><strong>频繁项目集的子集是频繁项目集，非频繁项目集的超级是非频繁项目集</strong></p>
<h3 id="apriori算法-伪代码必考"><a href="#apriori算法-伪代码必考" class="headerlink" title="apriori算法(伪代码必考)"></a>apriori算法(伪代码必考)</h3><p><strong>伪代码</strong></p>
<img src="/images/image-20221117155706261.png" alt="image-20221117155706261" style="zoom:67%;" />

<p><strong>主要步骤</strong></p>
<img src="/images/image-20221117155759820.png" alt="image-20221117155759820" style="zoom:67%;" />



<img src="/images/image-20221117155940246.png" alt="image-20221117155940246" style="zoom:67%;" />

<h3 id="Close算法（闭合项集计算必考）"><a href="#Close算法（闭合项集计算必考）" class="headerlink" title="Close算法（闭合项集计算必考）"></a>Close算法（闭合项集计算必考）</h3><p><strong>原理</strong></p>
<p>一个频繁闭合项目集的所有闭合子集一定是频繁的，一个非频繁闭合项目集的所有闭合超集一定是非频繁的。</p>
<p><strong>伪代码</strong></p>
<img src="/images/image-20221117160655449.png" alt="image-20221117160655449" style="zoom: 80%;" />

<img src="/images/image-20221117160732421.png" alt="image-20221117160732421" style="zoom:80%;" />

<img src="/images/image-20221117160752506.png" alt="image-20221117160752506" style="zoom:80%;" />

<img src="/images/image-20221117160818926.png" alt="image-20221117160818926" style="zoom:80%;" />

<p><strong>算法示例（必考</strong>）</p>
<img src="/images/image-20221117161340553.png" alt="image-20221117161340553" style="zoom:80%;" />

<img src="/images/image-20221117161409624.png" alt="image-20221117161409624" style="zoom:80%;" />

<img src="/images/image-20221117161452894.png" alt="image-20221117161452894" style="zoom:80%;" />

<img src="/images/image-20221117161525291.png" alt="image-20221117161525291" style="zoom:80%;" />

<p><strong>计算闭合项集及支持度（P85-P87）</strong></p>
<p><img src="/images/image-20221117162551122.png" alt="image-20221117162551122"></p>
<h2 id="第四章-分类方法"><a href="#第四章-分类方法" class="headerlink" title="第四章 分类方法"></a>第四章 分类方法</h2><p>分类的目的是学会一个分类函数或分类模型，该模型能把数据库中的数据项映射到给定类别中的某一个类别。</p>
<h3 id="基本概念和步骤"><a href="#基本概念和步骤" class="headerlink" title="基本概念和步骤"></a>基本概念和步骤</h3><ol>
<li>基本概念</li>
</ol>
<p>给定一个数据库$D&#x3D;{t_1,t_2,…,t_n}$和一组类$C&#x3D;{C_1,C_2,…,C_n}$，分类问题是去确定一个映射$f: D\to C$，每个元组$t_i$被分配到一个类中。一个类$C_i$包含映射到该类中的所有元组，即$C_j&#x3D;{f(t_i)&#x3D;C_j,1 \le i \le n,$且$t_i \in D }$。</p>
<ol>
<li>步骤</li>
</ol>
<p>通常分为两个步骤：建模和使用</p>
<ol>
<li>建模<br>简历一个模型，描述预定的数据类集或概念集。<br>通过分析由属性描述的数据库元组来构造模型。数据元组也称样本、实例或对象。为建立模型而被分析的数据元组形成训练数据集。<br>通常，学习模型用分类规则、决策树或等式、不等式、规则式等形式提供。这些规则可以为以后的数据样本分类，也能对数据库的内容提供更好的理解。</li>
<li>使用<br>使用模型进行分类。</li>
</ol>
<h3 id="KNN算法（伪代码必考）"><a href="#KNN算法（伪代码必考）" class="headerlink" title="KNN算法（伪代码必考）"></a>KNN算法（伪代码必考）</h3><p><strong>伪代码（必考</strong>）</p>
<img src="/images/image-20221117164319335.png" alt="image-20221117164319335" style="zoom:80%;" />

<p><strong>算法示例</strong></p>
<img src="/images/image-20221117164409710.png" alt="image-20221117164409710" style="zoom:80%;" />

<img src="/images/image-20221117164433723.png" alt="image-20221117164433723" style="zoom:80%;" />

<img src="/images/image-20221117164454753.png" alt="image-20221117164454753" style="zoom:80%;" />

<h3 id="ID3算法（伪代码必考）"><a href="#ID3算法（伪代码必考）" class="headerlink" title="ID3算法（伪代码必考）"></a>ID3算法（伪代码必考）</h3><p><strong>基本概念</strong></p>
<ul>
<li>决策树中每一个非叶节点对应着一个非类别属性，树枝代表这个属性的值。一个叶节点代表从树根到叶节点之间的路径对应的记录所属的类别属性值。</li>
<li>每一个非叶节点都将与属性中最大信息量的非类别属性相关联。</li>
<li>采用信息增益来选择出能够最好地将样本分类的属性。</li>
</ul>
<ol>
<li><p><strong>信息熵：</strong>是对随机变量不确定度的度量，熵越大，随机变量的不确定性就越大。如果一个事件发生的概率是$p(x)$，则其信息熵为$H&#x3D;log\frac{1}{p(x)}$</p>
</li>
<li><p>信息增益（information gain）：是针对一个一个特征而言的，就是看一个特征，系统有它和没有它时的信息量各是多少，两者的差值就是这个特征给系统带来的信息量，即信息增益。</p>
</li>
</ol>
<p><strong>伪代码（必考</strong>）</p>
<p><img src="/images/image-20221117165412997.png" alt="image-20221117165412997"></p>
<h3 id="EM算法（定义必考）"><a href="#EM算法（定义必考）" class="headerlink" title="EM算法（定义必考）"></a>EM算法（定义必考）</h3><p><strong>贝叶斯定理</strong><br>$$<br>P(H|X) &#x3D; \frac{(PX|H)P(H)}{P(X)}<br>$$</p>
<p><strong>EM算法定义（必考）</strong></p>
<p>在概率模型中寻找参数最大似然估计或者最大后验预计的算法。用于寻址，依赖于不可观察的隐形变量的概率模型中,参数的最大似然预计。</p>
<img src="/images/image-20221117170919238.png" alt="image-20221117170919238" style="zoom:80%;" />

<p><strong>步骤</strong></p>
<p><strong>步骤</strong>（基本必考）：最大期望算法经过两个步骤交替进行计算</p>
<ul>
<li><p>第一步是计算期望（E），利用对隐藏变量的现有预计值，计算其最大似然预计值。</p>
<p>$$<br>Q(h\prime|h)\leftarrow E[ln\ P(Y|h\prime)]<br>$$</p>
</li>
<li><p>第二步是最大化（M）。最大化在E步上求得的最大似然值来计算参数的值。M步上找到的参数预计值被用于下一个E步计算中，这个过程不断交替进行。</p>
</li>
</ul>
<h2 id="第五章-聚类方法"><a href="#第五章-聚类方法" class="headerlink" title="第五章 聚类方法"></a>第五章 聚类方法</h2><h3 id="K-means算法（伪代码必考）"><a href="#K-means算法（伪代码必考）" class="headerlink" title="K-means算法（伪代码必考）"></a>K-means算法（伪代码必考）</h3><p><strong>算法基本思想</strong></p>
<ol>
<li><p>划分聚类方法</p>
<p>给定一个有n个对象的数据集，划分聚类技术将构造数据k个划分，每个划分就代表一个簇，k&lt;&#x3D;n。也就是说，它将数据划分为k个簇，而且这k个划分满足下列条件：</p>
<ul>
<li>每一个簇至少包含一个对象</li>
<li>每一个对象属于且仅属于一个簇。</li>
</ul>
<p>对于给定的k，先初始划分，再反复迭代改变划分，使每一次都比前一次更好。即同一簇中的对象越近越好，不同簇中的对象越远越</p>
<p>好。最小化所有对象与其参照点之间的相异度之和。</p>
</li>
<li><p>k-平均算法</p>
<ul>
<li><p>相似度的计算根据一个簇中对象的平均值来计算</p>
</li>
<li><p>首先随机的选择k个对象，每个对象初始地代表了一个簇地平均值或中心。对剩余地每个对象根据其与各个簇中心的距离，将其赋给最近的簇。然后重新计算每个簇的平均值，不断重复。</p>
</li>
<li><p>准则函数为<br>$$<br>E &#x3D; \sum_{i&#x3D;1}^{k} \sum_{i\in C_i} |x-\overline x_i|^2<br>$$</p>
<img src="/images/image-20221117180311620.png" alt="image-20221117180311620" style="zoom: 80%;" /></li>
</ul>
</li>
</ol>
<p><strong>伪代码（必考</strong>）</p>
<img src="/images/image-20221117180502715.png" alt="image-20221117180502715" style="zoom:80%;" />

<h3 id="k-medoids方法-PAM算法-（定义必考）"><a href="#k-medoids方法-PAM算法-（定义必考）" class="headerlink" title="k-medoids方法(PAM算法)（定义必考）"></a>k-medoids方法(PAM算法)（定义必考）</h3><p><strong>定义（必考</strong>）</p>
<p>k-means算法对于孤立点是敏感的。为了解决这个问题，不采用簇中的平均值作为参照点，可以选用簇中<strong>位置最中心的对象</strong>，即中心点作为参照点。这样划分方法仍然是基于最小化所有对象于其参照点之间的相异度之和的原则来执行的。</p>
<img src="/images/image-20221117180815186.png" alt="image-20221117180815186" style="zoom:80%;" />

<img src="/images/image-20221117181540715.png" alt="image-20221117181540715" style="zoom: 67%;" />

<p><strong>伪代码</strong></p>
<img src="/images/image-20221117181144810.png" alt="image-20221117181144810" style="zoom: 80%;" />

<h3 id="AGNES算法"><a href="#AGNES算法" class="headerlink" title="AGNES算法"></a>AGNES算法</h3><p>自底向上凝聚算法（AGglomerative NESting）</p>
<p><strong>基本思想</strong></p>
<p>将每个对象作为一个簇，然后这些簇根据某些准则被一步步地合并。</p>
<p><strong>伪代码</strong></p>
<img src="/images/image-20221117181828826.png" alt="image-20221117181828826" style="zoom:80%;" />

<h3 id="DIANA算法"><a href="#DIANA算法" class="headerlink" title="DIANA算法"></a>DIANA算法</h3><p>DIANA（Divisive ANAlysis）算法属于分类地层次聚类。</p>
<p><strong>基本思想</strong></p>
<p>它采用一种自顶向下的策略，首先将所有对象置于一个簇中，然后逐渐细分为越来越小的簇，直到每个对象自成一簇，或者达到了某个终结条件。</p>
<p><strong>伪代码</strong></p>
<img src="/images/image-20221117182029041.png" alt="image-20221117182029041" style="zoom:80%;" />

<h3 id="DBSCAN算法"><a href="#DBSCAN算法" class="headerlink" title="DBSCAN算法"></a>DBSCAN算法</h3><p><strong>DBSCAN：Density-Based Spatial Clustering of Applications with Noise，噪声环境下的密度聚类算法</strong></p>
<p><strong>基本思想</strong></p>
<img src="/images/image-20221117182915374.png" alt="image-20221117182915374" style="zoom:80%;" />

<img src="/images/image-20221117182953001.png" alt="image-20221117182953001" style="zoom:80%;" />

<p><strong>描述</strong></p>
<img src="/images/image-20221117182634942.png" alt="image-20221117182634942" style="zoom:80%;" />

<p><strong>伪代码</strong></p>
<img src="/images/image-20221117182712477.png" alt="image-20221117182712477" style="zoom:80%;" />

<h2 id="第六章-时间序列和序列模式挖掘"><a href="#第六章-时间序列和序列模式挖掘" class="headerlink" title="第六章 时间序列和序列模式挖掘"></a>第六章 时间序列和序列模式挖掘</h2><p><strong>时间序列数据挖掘通过研究信息的时间特性，深入洞悉事物进化的机制，是获得知识的有效途径。</strong></p>
<p>时间序列挖掘在<strong>宏观的经济预测、市场营销、客流量分析、太阳黑子数、月降水量、河流流量、股票价格变动等</strong>众多领域得到应用。事实上，<strong>社会、科学、经济、技术等领域</strong>中广泛存在着大量的时间序列数据有待进一步的分析和处理。</p>
<p><strong>时间序列(Time Series)挖掘：</strong>就是要从大量的时间序列数据中提取人们事先不知道的、但又是潜在有用的与时间属性相关的信息和知识，并用于短期、中期或长期预测，指导人们的社会、经济、军事和生活等行为。通过对过去历史行为的客观记录分析，揭示其内在规律，进而完成预测未来行为等决策性工作。</p>
<h2 id="第七章-Web挖掘技术"><a href="#第七章-Web挖掘技术" class="headerlink" title="第七章 Web挖掘技术"></a>第七章 Web挖掘技术</h2><h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>利用数据挖掘的思想和方法，在Web上挖掘出有用的信息</p>
<h3 id="PageRank算法（伪代码必考）"><a href="#PageRank算法（伪代码必考）" class="headerlink" title="PageRank算法（伪代码必考）"></a>PageRank算法（伪代码必考）</h3><p><strong>基本思想</strong></p>
<p>如果一个网页被很多其他网页链接到的话说话这个网页比较重要，也就是PageRank值会相对较高②如果一个PageRank值很高的网页链接到一个其他的网页，那么被链接到的网页的PageRank值会相应地因此而提高。</p>
<p><strong>伪代码（必考）</strong><br><img src="/images/image-20221117183844439.png" alt="image-20221117183844439" style="zoom:80%;" /></p>

  </div>
</article>
</div>
  <div><!-- 目录 -->
<div class="toc-main">
  <div class="toc-container">
    <div class="toc-name">
      <i class="fa-solid fa-list-ul toc-icon"></i>
      目录
    </div>
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%80%83%E8%AF%95%E9%A2%98%E5%9E%8B"><span class="toc-number">1.</span> <span class="toc-text">考试题型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%87%8D%E7%82%B9%E7%AE%97%E6%B3%95"><span class="toc-number">2.</span> <span class="toc-text">重点算法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E7%AB%A0%E3%80%81%E7%AC%AC%E4%BA%8C%E7%AB%A0"><span class="toc-number">3.</span> <span class="toc-text">第一章、第二章</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A"><span class="toc-number">3.1.</span> <span class="toc-text">名词解释</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%E7%AB%A0-%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E6%8C%96%E6%8E%98%E7%90%86%E8%AE%BA%E5%92%8C%E6%96%B9%E6%B3%95"><span class="toc-number">4.</span> <span class="toc-text">第三章 关联规则挖掘理论和方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95"><span class="toc-number">4.1.</span> <span class="toc-text">基本概念和解决方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A1%B9%E7%9B%AE%E9%9B%86%E7%A9%BA%E9%97%B4%E7%90%86%E8%AE%BA"><span class="toc-number">4.2.</span> <span class="toc-text">项目集空间理论</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#apriori%E7%AE%97%E6%B3%95-%E4%BC%AA%E4%BB%A3%E7%A0%81%E5%BF%85%E8%80%83"><span class="toc-number">4.3.</span> <span class="toc-text">apriori算法(伪代码必考)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Close%E7%AE%97%E6%B3%95%EF%BC%88%E9%97%AD%E5%90%88%E9%A1%B9%E9%9B%86%E8%AE%A1%E7%AE%97%E5%BF%85%E8%80%83%EF%BC%89"><span class="toc-number">4.4.</span> <span class="toc-text">Close算法（闭合项集计算必考）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%E7%AB%A0-%E5%88%86%E7%B1%BB%E6%96%B9%E6%B3%95"><span class="toc-number">5.</span> <span class="toc-text">第四章 分类方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%AD%A5%E9%AA%A4"><span class="toc-number">5.1.</span> <span class="toc-text">基本概念和步骤</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#KNN%E7%AE%97%E6%B3%95%EF%BC%88%E4%BC%AA%E4%BB%A3%E7%A0%81%E5%BF%85%E8%80%83%EF%BC%89"><span class="toc-number">5.2.</span> <span class="toc-text">KNN算法（伪代码必考）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ID3%E7%AE%97%E6%B3%95%EF%BC%88%E4%BC%AA%E4%BB%A3%E7%A0%81%E5%BF%85%E8%80%83%EF%BC%89"><span class="toc-number">5.3.</span> <span class="toc-text">ID3算法（伪代码必考）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#EM%E7%AE%97%E6%B3%95%EF%BC%88%E5%AE%9A%E4%B9%89%E5%BF%85%E8%80%83%EF%BC%89"><span class="toc-number">5.4.</span> <span class="toc-text">EM算法（定义必考）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%94%E7%AB%A0-%E8%81%9A%E7%B1%BB%E6%96%B9%E6%B3%95"><span class="toc-number">6.</span> <span class="toc-text">第五章 聚类方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#K-means%E7%AE%97%E6%B3%95%EF%BC%88%E4%BC%AA%E4%BB%A3%E7%A0%81%E5%BF%85%E8%80%83%EF%BC%89"><span class="toc-number">6.1.</span> <span class="toc-text">K-means算法（伪代码必考）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#k-medoids%E6%96%B9%E6%B3%95-PAM%E7%AE%97%E6%B3%95-%EF%BC%88%E5%AE%9A%E4%B9%89%E5%BF%85%E8%80%83%EF%BC%89"><span class="toc-number">6.2.</span> <span class="toc-text">k-medoids方法(PAM算法)（定义必考）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#AGNES%E7%AE%97%E6%B3%95"><span class="toc-number">6.3.</span> <span class="toc-text">AGNES算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DIANA%E7%AE%97%E6%B3%95"><span class="toc-number">6.4.</span> <span class="toc-text">DIANA算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DBSCAN%E7%AE%97%E6%B3%95"><span class="toc-number">6.5.</span> <span class="toc-text">DBSCAN算法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E5%85%AD%E7%AB%A0-%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E5%92%8C%E5%BA%8F%E5%88%97%E6%A8%A1%E5%BC%8F%E6%8C%96%E6%8E%98"><span class="toc-number">7.</span> <span class="toc-text">第六章 时间序列和序列模式挖掘</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%83%E7%AB%A0-Web%E6%8C%96%E6%8E%98%E6%8A%80%E6%9C%AF"><span class="toc-number">8.</span> <span class="toc-text">第七章 Web挖掘技术</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-number">8.1.</span> <span class="toc-text">基本概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#PageRank%E7%AE%97%E6%B3%95%EF%BC%88%E4%BC%AA%E4%BB%A3%E7%A0%81%E5%BF%85%E8%80%83%EF%BC%89"><span class="toc-number">8.2.</span> <span class="toc-text">PageRank算法（伪代码必考）</span></a></li></ol></li></ol>
  </div>
</div></div>
</div>

      </div>
      <div class="layout-footer">
        <footer class="footer">
  <div class="f-center">
    <p class="author">
      Theme is 
      <a href="/" target="_blank" class="footer-link">
        light
      </a> 
      by 
      <a href="https://github.com/7UP-hue" target="_blank" class="footer-link">
        7UP-hue
      </a>
    </p>    
    <p class="powered">
      Powered by 
      <a href="https://hexo.io/" target="_blank" rel="nofollow" class="footer-link">
        hexo
      </a> 
      &copy; 2022
    </p>
  </div>
</footer>
      </div>
      <div class="scroll-top scroll-top-show"><i class="fa-solid fa-circle-arrow-up"></i></div>
    </div>
  </body>
</html>
